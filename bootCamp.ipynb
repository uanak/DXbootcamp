{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bootCamp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPv6kMEHg9HxurPmUKa/Lji",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uanak/DXbootcamp/blob/main/bootCamp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0Q_DUOe42oO"
      },
      "source": [
        "各種インストール\n",
        "mecab(要素解析）,pytorch,kmeans（クラスタ）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tIWqUETfXad"
      },
      "source": [
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.7\n",
        "!pip install -U torch torchvision\n",
        "!pip install kmeans-pytorch\n",
        "\n",
        "import MeCab\n",
        "import numpy as np\n",
        "import torch\n",
        "from kmeans_pytorch import kmeans\n",
        "from gensim import corpora, matutils\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvLmDfLDnsYC",
        "outputId": "68840774-e201-4a39-9ccc-4d2c57bb4845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "mecab = MeCab.Tagger(\"-Ochasen\")\n",
        "mecab.parse('')\n",
        "\n",
        "def bunkai(contents):\n",
        "    ret = []\n",
        "    for  content in contents:\n",
        "        ret.append(bunkaiChi(content))\n",
        "    return ret\n",
        "\n",
        "def bunkaiChi(content):\n",
        "  return [token for token in doMecab(content)]\n",
        "\n",
        "def doMecab(text):\n",
        "  nodes = mecab.parseToNode(text)\n",
        "  while nodes:\n",
        "    if nodes.feature.split(',')[0] == '名詞':\n",
        "      yield nodes.surface.lower()\n",
        "    nodes = nodes.next\n",
        "\n",
        "\n",
        "test1 = [\"トランプ氏、2州で集会強行　コロナ拡大地域、熱気演出\",\n",
        "         \"東京都 新型コロナ 2人が死亡 新たに132人感染確認\",\n",
        "         \"iPhoneやApple Watchの「Suica」と「PASMO」って何が違う？　比較してみよう【2020年最新版\"]\n",
        "wordlists = bunkai(test1)\n",
        "\n",
        "# wordlists=bunkai()\n",
        "print(wordlists)\n",
        "\n",
        "jisho = corpora.Dictionary(wordlists)\n",
        "print(jisho.token2id)\n",
        "courpus = [jisho.doc2bow(word) for word in wordlists]\n",
        "print(courpus)\n",
        "\n",
        "def toVec(wordlist):\n",
        "  vecs=[]\n",
        "  for word in wordlist:\n",
        "    vecs.append(jisho.doc2bow(word))\n",
        "  return vecs \n",
        "\n",
        "data = torch.tensor(toVec(wordlists))\n",
        "# print(data)\n",
        "\n",
        "# dense = list(matutils.corpus2dense([vec], num_terms=len(jisho)).T[0])\n",
        "# print(dense)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['トランプ', '氏', '2', '州', '集会', '強行', 'コロナ', '拡大', '地域', '熱気', '演出'], ['東京', '都', '新型', 'コロナ', '2', '人', '死亡', '新た', '132', '人', '感染', '確認'], ['iphone', 'apple', 'watch', 'suica', 'pasmo', '何', '比較', '2020', '年', '最新', '版']]\n",
            "{'2': 0, 'コロナ': 1, 'トランプ': 2, '地域': 3, '州': 4, '強行': 5, '拡大': 6, '氏': 7, '演出': 8, '熱気': 9, '集会': 10, '132': 11, '人': 12, '感染': 13, '新た': 14, '新型': 15, '東京': 16, '死亡': 17, '確認': 18, '都': 19, '2020': 20, 'apple': 21, 'iphone': 22, 'pasmo': 23, 'suica': 24, 'watch': 25, '何': 26, '年': 27, '最新': 28, '比較': 29, '版': 30}\n",
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1)], [(0, 1), (1, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1)], [(20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1)]]\n",
            "tensor([[[ 0,  1],\n",
            "         [ 1,  1],\n",
            "         [ 2,  1],\n",
            "         [ 3,  1],\n",
            "         [ 4,  1],\n",
            "         [ 5,  1],\n",
            "         [ 6,  1],\n",
            "         [ 7,  1],\n",
            "         [ 8,  1],\n",
            "         [ 9,  1],\n",
            "         [10,  1]],\n",
            "\n",
            "        [[ 0,  1],\n",
            "         [ 1,  1],\n",
            "         [11,  1],\n",
            "         [12,  2],\n",
            "         [13,  1],\n",
            "         [14,  1],\n",
            "         [15,  1],\n",
            "         [16,  1],\n",
            "         [17,  1],\n",
            "         [18,  1],\n",
            "         [19,  1]],\n",
            "\n",
            "        [[20,  1],\n",
            "         [21,  1],\n",
            "         [22,  1],\n",
            "         [23,  1],\n",
            "         [24,  1],\n",
            "         [25,  1],\n",
            "         [26,  1],\n",
            "         [27,  1],\n",
            "         [28,  1],\n",
            "         [29,  1],\n",
            "         [30,  1]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsFcvZgVkdS1"
      },
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "    # モデルで使う各ネットワークをコンストラクタで定義\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        # 親クラスのコンストラクタ。決まり文句\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        # 隠れ層の次元数。これは好きな値に設定しても行列計算の過程で出力には出てこないので。\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # インプットの単語をベクトル化するために使う\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # LSTMの隠れ層。これ１つでOK。超便利。\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "        # softmaxのLog版。dim=0で列、dim=1で行方向を確率変換。\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    # 順伝播処理はforward関数に記載\n",
        "    def forward(self, sentence):\n",
        "        # 文章内の各単語をベクトル化して出力。2次元のテンソル\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        # 2次元テンソルをLSTMに食わせられる様にviewで３次元テンソルにした上でLSTMへ流す。\n",
        "        # 上記で説明した様にmany to oneのタスクを解きたいので、第二戻り値だけ使う。\n",
        "        _, lstm_out = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        # lstm_out[0]は３次元テンソルになってしまっているので2次元に調整して全結合。\n",
        "        tag_space = self.hidden2tag(lstm_out[0].view(-1, HIDDEN_DIM))\n",
        "        # softmaxに食わせて、確率として表現\n",
        "        tag_scores = self.softmax(tag_space)\n",
        "        return tag_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaDWi6aS40-Q"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwPkx0UCq1C3",
        "outputId": "51cd1ca1-294a-49cf-c047-a6641b3ca38d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "\n",
        "dataframe= pd.read_csv('drive/My Drive/dxboot/test.CSV')\n",
        "\n",
        "x=[]\n",
        "y=[]\n",
        "for dataframe:\n",
        "  i=1\n",
        "  dataframe.iloc[1,1]\n",
        "\n",
        "print(data)\n",
        "# DataLoaderの設定\n",
        "batch_size = 50\n",
        "train_loader = DataLoader(data, \n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True)\n",
        "test_loader = DataLoader(data,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=False)\n",
        "\n",
        "\n",
        "datasets = pd.DataFrame(columns=[\"title\", \"category\"])\n",
        "\n",
        "datasets.head()\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(1, 1024)  # 全結合層\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 1)  # バッチサイズ×入力の数\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "      D                                       マスクで顔を隠す独女たち\n",
            "0     D                        薄っぺらい親友関係が増殖中？ 女の友情はきょわい〜！？\n",
            "1     D             【オトナ女子映画部】“隙だらけ”のウザい女に学ぶ男心のつかみ方『乱暴と待機』\n",
            "2     D  女医が教えるオンナの体のウソホント vol.10「体の変化とホルモン分泌の周期」presen...\n",
            "3     D                          結婚相手に妥協できるもの、できないもの　（男性編）\n",
            "4     D  女医が教えるオンナの体のウソホント vol.9「体温上げて、熱いオンナになるべし！」pres...\n",
            "...  ..                                                ...\n",
            "4267  K                             「2012年期待の女優ランキング」に非難続出\n",
            "4268  K                                   ドリムス出演のMステ視聴率が話題\n",
            "4269  K                          被災者イジメ「津波で死ねばよかったのに」に非難殺到\n",
            "4270  K                          バットの上に長時間正座…プロ野球界の主従関係を非難\n",
            "4271  K                              オセロ中島に対する松嶋のコメントに批判の声\n",
            "\n",
            "[4272 rows x 2 columns]\n",
            "Net(\n",
            "  (fc1): Linear(in_features=1, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pInFx6rvq07X"
      },
      "source": [
        "class news(Dataset):\n",
        "    def __init__(self, csv_path):\n",
        "        # csv ファイルを読み込む。\n",
        "        df = pd.read_csv(csv_path)\n",
        "        data = df.iloc[:, 1:]  # データ (2 ~ 14列目)\n",
        "        labels = df.iloc[:, 0]  # ラベル (1列目)\n",
        "        # データを標準化する。\n",
        "        data = normalize(data)\n",
        "        # クラス ID を 0 始まりにする。[1, 2, 3] -> [0, 1, 2]\n",
        "        labels -= 1\n",
        "\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"サンプルを返す。\n",
        "        \"\"\"\n",
        "        return self.data[index], self.labels[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"csv の行数を返す。\n",
        "        \"\"\"\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwuR7JJ6i4cs"
      },
      "source": [
        "# data\n",
        "data_size, dims, num_clusters = 1000, 2, 3\n",
        "x = np.random.randn(data_size, dims) / 6\n",
        "x = torch.from_numpy(x)\n",
        "\n",
        "\n",
        "\n",
        "s = pd.Series([title, cat], index=datasets.columns)\n",
        "datasets = datasets.append(s, ignore_index=True)\n",
        "datasets = datasets.sample(frac=1).reset_index(drop=True)\n",
        "datasets.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}